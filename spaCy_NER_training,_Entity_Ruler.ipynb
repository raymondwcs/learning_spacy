{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('nlp': conda)"
    },
    "interpreter": {
      "hash": "351231c1f7e72ec05ff176d4b7814d8150b7ea6b9dc70ba3501701b8f740a37d"
    },
    "colab": {
      "name": "spaCy NER training, Entity Ruler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raymondwcs/learning_spacy/blob/main/spaCy_NER_training%2C_Entity_Ruler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TcIJUPPdlzC"
      },
      "source": [
        "This example demonstrates how to use rules-augmented model-based NER to locate stock codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xmMkwz0dVMo",
        "outputId": "f9fa5cb8-c697-44d0-eb06-331e66730a5d"
      },
      "source": [
        "!pip install --quiet -U spacy\n",
        "!python -m spacy download zh_core_web_lg\n",
        "!git clone http://github.com/raymondwcs/learning_spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zh-core-web-lg==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/zh_core_web_lg-3.1.0/zh_core_web_lg-3.1.0-py3-none-any.whl (603.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 603.8 MB 8.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy-pkuseg<0.1.0,>=0.0.27 in /usr/local/lib/python3.7/dist-packages (from zh-core-web-lg==3.1.0) (0.0.28)\n",
            "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from zh-core-web-lg==3.1.0) (3.1.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (8.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (21.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (4.62.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.10)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.7/dist-packages (from spacy-pkuseg<0.1.0,>=0.0.27->zh-core-web-lg==3.1.0) (0.29.24)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.0.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('zh_core_web_lg')\n",
            "fatal: destination path 'learning_spacy' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMcLQHQ5dAAA"
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "from spacy import displacy\n",
        "import re\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vnwMcEmdAAC"
      },
      "source": [
        "nlp = spacy.load('zh_core_web_lg')\n",
        "nlp.tokenizer.initialize(pkuseg_model=\"./learning_spacy/spacy_pkuseg/models\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJsI4DaOJbYi"
      },
      "source": [
        "# Part 1 - Train model-based NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOkZtiKAhjnQ"
      },
      "source": [
        "## Data for training the model-based NER\n",
        "Training can also be done via CLI.  Details below.\n",
        "\n",
        "https://github.com/raymondwcs/learning_spacy/tree/main/NER_Training_CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smi8zsDQdAAD"
      },
      "source": [
        "TRAIN_DATA = [\n",
        "    (\"ä¸€é½Šä¿‚åœ‹ä¼æˆä»½è‚¡èª¿æ•´æœŸé–“ å¤§å®¶ä¸€é½Šä¸å•åƒ¹æƒè²¨ å°¤å…¶æ˜¯386 857 æˆä»½è‚¡ä½”æŒ‡æ•¸æ¯”é‡åªä¿‚5%å·¦å³ å†‡å’©å—æ–°è¨ˆæ³•å½±éŸ¿ æŒ¾æ­»ç­æ­ç¾é¬¼ä½¬ æ¸¯è‚¡10æœˆ29000 é å¿…æŒ¾ä¹‹\", \n",
        "        {\"entities\": [(26,29,\"STOCK\"),(30,33,\"STOCK\")]}),\n",
        "    (\"é«˜ç››ï¼šç¶­æŒå°é¨°è¨Š(0700)è²·å…¥è©•ç´š ç›®æ¨™åƒ¹705æ¸¯å…ƒé«˜ç››ç™¼è¡¨å ±å‘ŠæŒ‡,èˆ‡é¨°è¨Šç®¡ç†å±¤æ–¼è·¯æ¼”æ´»å‹•æºé€šå¾Œ,é‡ç”³å°é¨°è¨Šå˜…ç©æ¥µæ­£é¢ç‡æ³•ã€‚\",\n",
        "        {\"entities\": [(6,8,\"STOCK\")]}),\n",
        "    (\"ä¸­é›»ã€åŒ¯æ§ã€æ’å¤§8æœˆæš´å‡8.5%ã€‚\",\n",
        "        {'entities': [(0,2,\"STOCK\"),(3,5,\"STOCK\"),(6,8,\"STOCK\")]}),\n",
        "    (\"åŒ¯æ§(00005)å°‡æ–¼ä¸‹å‘¨ä¸€ï¼ˆ2æ—¥ï¼‰å…¬å¸ƒ2021å¹´åº¦ä¸­æœŸæ¥­ç¸¾ã€‚\",\n",
        "        {'entities': [(0,2,\"STOCK\")]}),\n",
        "    (\"ä¸­é›»ï¼ŒåŒ¯æ§ï¼Œæ¸¯äº¤æ‰€é½Šé½Šè·Œ8.5%é‡‘èæµ·å˜¯å¾Œæœ€å·®ã€‚\",\n",
        "        {\"entities\": [(0,2,\"STOCK\"),(3,5,\"STOCK\"),(6,9,\"STOCK\")]}),    \n",
        "    (\"æ¸¯ç‡ˆå°‡æ¢å¾©æ´¾æ¯\",\n",
        "        {\"entities\": [(0,2,\"STOCK\")]})\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "451MmG4PdAAD"
      },
      "source": [
        "ner=nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Adding labels to the `ner`\n",
        "for _, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnyzPNiBhu5Y"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M0x6E4HdAAE",
        "outputId": "326d3318-7aea-4108-a2da-078f21a26375"
      },
      "source": [
        "epoch = 50\n",
        "optimizer = nlp.resume_training()\n",
        "\n",
        "# get names of other pipes to disable them during training\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "  for itn in range(epoch):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = spacy.util.minibatch(TRAIN_DATA,size=2)\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        example = []\n",
        "        for i in range(len(texts)):\n",
        "          doc = nlp.make_doc(texts[i])\n",
        "          example.append(Example.from_dict(doc, annotations[i]))\n",
        "        nlp.update(example,drop=0.2,sgd=optimizer,losses=losses)\n",
        "    print(\"Losses\", losses)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses {'ner': 30.66365236725184}\n",
            "Losses {'ner': 20.535725836958818}\n",
            "Losses {'ner': 18.337547548141224}\n",
            "Losses {'ner': 16.068195706656272}\n",
            "Losses {'ner': 13.498557920853894}\n",
            "Losses {'ner': 12.493912998414066}\n",
            "Losses {'ner': 9.760448115241282}\n",
            "Losses {'ner': 6.151994594813331}\n",
            "Losses {'ner': 4.536754130217901}\n",
            "Losses {'ner': 3.279793493113438}\n",
            "Losses {'ner': 0.2823935921201741}\n",
            "Losses {'ner': 0.574943195942957}\n",
            "Losses {'ner': 0.6645287696830977}\n",
            "Losses {'ner': 0.04638215958796692}\n",
            "Losses {'ner': 0.0012096859049819531}\n",
            "Losses {'ner': 0.004151983546153217}\n",
            "Losses {'ner': 0.0332430002578767}\n",
            "Losses {'ner': 3.0275319816197946e-05}\n",
            "Losses {'ner': 0.00024175256444800838}\n",
            "Losses {'ner': 1.1689136720023962e-06}\n",
            "Losses {'ner': 1.1129212454450931e-07}\n",
            "Losses {'ner': 2.325519552073216e-06}\n",
            "Losses {'ner': 3.2701564812786366e-07}\n",
            "Losses {'ner': 1.8495704051915652e-08}\n",
            "Losses {'ner': 2.1419984237256308e-05}\n",
            "Losses {'ner': 3.146855669003286e-05}\n",
            "Losses {'ner': 4.188323901551126e-06}\n",
            "Losses {'ner': 2.0774960012571178e-07}\n",
            "Losses {'ner': 4.765001773972794e-08}\n",
            "Losses {'ner': 3.491139816769603e-06}\n",
            "Losses {'ner': 1.042934359289179e-09}\n",
            "Losses {'ner': 2.95219129955472e-09}\n",
            "Losses {'ner': 3.8505291268010035e-08}\n",
            "Losses {'ner': 5.758541935217543e-09}\n",
            "Losses {'ner': 1.8231310248608724e-09}\n",
            "Losses {'ner': 5.271426256132006e-09}\n",
            "Losses {'ner': 2.960461014191118e-08}\n",
            "Losses {'ner': 6.691773141659981e-10}\n",
            "Losses {'ner': 3.486990648026783e-09}\n",
            "Losses {'ner': 3.005595405854702e-08}\n",
            "Losses {'ner': 5.514146962312102e-06}\n",
            "Losses {'ner': 4.720915502358146e-05}\n",
            "Losses {'ner': 5.742582371129782e-09}\n",
            "Losses {'ner': 7.497429612842989e-05}\n",
            "Losses {'ner': 1.2364615918267787e-05}\n",
            "Losses {'ner': 1.0929880660226879e-06}\n",
            "Losses {'ner': 1.1808027844554104e-07}\n",
            "Losses {'ner': 4.077384782160743e-08}\n",
            "Losses {'ner': 3.1707432859465843e-09}\n",
            "Losses {'ner': 1.7455392301875315e-07}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMezKSPYe7sN"
      },
      "source": [
        "## Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHvgsUX8dAAF"
      },
      "source": [
        "for text, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    # print(text,ent)\n",
        "    # print(text[ent[0]:ent[1]])\n",
        "    doc = nlp(text)\n",
        "    char_span = doc.char_span(ent[0],ent[1])\n",
        "    if char_span is None:  # start and end don't map to tokens\n",
        "        print(\"Misaligned tokens\", text, ent)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTnedeX8fDKV"
      },
      "source": [
        "## Save trained model to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXhK4SAvdAAG"
      },
      "source": [
        "nlp.to_disk('./ner_model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8mmNQm9JKL9"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h3GnKT2fIlT"
      },
      "source": [
        "## Load trained model from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F-h5fEhMqsj"
      },
      "source": [
        "nlp = spacy.load('./ner_model')\n",
        "nlp.tokenizer.initialize(pkuseg_model=\"./learning_spacy/spacy_pkuseg/models\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9P4z0cBM1xj"
      },
      "source": [
        "## Define custom rules for EntityRuler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_tRH7Dcw4ub",
        "outputId": "1e092219-3210-45f5-f3c8-5a3bdb5927d3"
      },
      "source": [
        "from pandas import *\n",
        "\n",
        "# https://docs.google.com/spreadsheets/d/1-btKGkOo_ywPeH8qTlJL0IKF1bxeaPEKTVhAOPeYAU8/edit?usp=sharing\n",
        "data = read_csv(\"stockcodes.csv\",dtype=str) \n",
        "\n",
        "stockcodes = data.iloc[:,1].to_list()   # STOCK\n",
        "orgs = data.iloc[:,2].to_list()         # ORG-S\n",
        "\n",
        "org_alias = ['5è™Ÿä»”','å¤§ç¬¨è±¡']     # ORG-S-A\n",
        "\n",
        "print(stockcodes[:10])\n",
        "print(orgs[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', '3', '4', '5', '6', '8', '10', '11', '12', '14']\n",
            "['ä¸­é›»æ§è‚¡', 'é¦™æ¸¯ä¸­è¯ç…¤æ°£', 'ä¹é¾å€‰é›†åœ˜', 'åŒ¯è±æ§è‚¡', 'é›»èƒ½å¯¦æ¥­', 'é›»è¨Šç›ˆç§‘', 'æ’éš†é›†åœ˜', 'æ’ç”ŸéŠ€è¡Œ', 'æ’åŸºåœ°ç”¢', 'å¸Œæ…èˆˆæ¥­']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTcU3mk1dAAG"
      },
      "source": [
        "patterns = [\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"IS_DIGIT\": True},{\"ORTH\":\".\"},{\"ORTH\": \"HK\"}]},\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"TEXT\": {\"REGEX\":\"\\d+\\.HK\"}}]},\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"ORTH\": \"(\"},{\"IS_DIGIT\": True},{\"ORTH\": \")\"}]},\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"IS_DIGIT\": True},{\"ENT_TYPE\": \"ORG\"}]},\n",
        "    {\"label\": \"STOCK2\", \"pattern\": [{\"POS\": \"NUM\"},{\"POS\": \"NOUN\"}]},\n",
        "    {\"label\": \"STOCK3\", \"pattern\": [{'TEXT': {'IN': stockcodes}}]},\n",
        "    {\"label\": \"ORG-S\", \"pattern\": [{'ORTH': {'IN': orgs}}]},\n",
        "    {\"label\": \"ORG-S-A\", \"pattern\": [{'ORTH': {'IN': org_alias}}]},\n",
        "]\n",
        "\n",
        "if \"entity_ruler\" in nlp.pipe_names:\n",
        "  nlp.remove_pipe(\"entity_ruler\")\n",
        "\n",
        "entity_ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
        "entity_ruler.add_patterns(patterns)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4L-It64-Dd0"
      },
      "source": [
        "## Check stock suffix ('STOCK2', 'STOCK3')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woJlgEDL-AOh",
        "outputId": "9df6368d-2628-47a5-fab3-a6d9c87a353e"
      },
      "source": [
        "from spacy.language import Language\n",
        "from spacy.tokens import Span\n",
        "\n",
        "def print_ent_details(ents):\n",
        "    ent_details = []\n",
        "    for ent in doc.ents:\n",
        "      ent_details.append([ent.text, ent.label_])\n",
        "    print('doc.ents: {}'.format(ent_details))\n",
        "\n",
        "@Language.component(\"check_stockno_suffix\")\n",
        "def remove_stockno_suffix(doc):\n",
        "    # print_ent_details(doc.ents)\n",
        "    new_ents = []\n",
        "    for i in range(len(doc.ents)):\n",
        "      if doc.ents[i].label_ == \"STOCK3\" or doc.ents[i].label_ == \"STOCK\":\n",
        "        token      = doc.ents[i]\n",
        "        next_token = doc[doc.ents[i].start+1]\n",
        "        # print('[{},{},{}]'.format(doc.ents[i].text,doc.ents[i].label_,next_token.text))\n",
        "        # print(token.text,next_token.text)\n",
        "        if  not re.search(r'[ä¸€äºŒä¸‰å››åäº”å…­ä¸ƒå…«ä¹åé›¶ç™¾åƒè¬å„„å£¹è²³åƒå„è‚†ä¼é™¸æŸ’æŒç–æ‹¾ä½°ä»Ÿ]+',token.text) and \\\n",
        "            not re.search(r'[èšŠè™Ÿ]',token.text) and \\\n",
        "            not re.search(r'[å…ƒæ–‡èšŠ]',next_token.text):\n",
        "          new_ent = Span(doc, doc.ents[i].start, doc.ents[i].end, label=\"STOCK\")\n",
        "          new_ents.append(new_ent)\n",
        "      else:\n",
        "        new_ents.append(doc.ents[i])\n",
        "    doc.ents = new_ents\n",
        "    # print_ent_details(doc.ents)\n",
        "    return doc\n",
        "\n",
        "# Add the component after the named entity recognizer\n",
        "if \"check_stockno_suffix\" in nlp.pipe_names:\n",
        "  nlp.remove_pipe(\"check_stockno_suffix\")\n",
        "\n",
        "nlp.add_pipe(\"check_stockno_suffix\", after=\"ner\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.remove_stockno_suffix>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOJnEtLcjpf"
      },
      "source": [
        "## Remove stock noun suffix ('STOCK2')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adxyitSpPqZs",
        "outputId": "5e7ac1ad-1d49-4fba-e179-acad3479029e"
      },
      "source": [
        "from spacy.language import Language\n",
        "from spacy.tokens import Span\n",
        "\n",
        "@Language.component(\"remove_stockno_suffix\")\n",
        "def remove_stockno_suffix(doc):\n",
        "    new_ents = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"STOCK2\":  #and ent.start != 0:\n",
        "            next_token = doc[ent.start + 1]\n",
        "            if next_token.pos_ == \"NOUN\":\n",
        "                new_ent = Span(doc, ent.start, ent.end - 1, label=\"STOCK\")\n",
        "                new_ents.append(new_ent)\n",
        "        else:\n",
        "            new_ents.append(ent)\n",
        "    doc.ents = new_ents\n",
        "    return doc\n",
        "\n",
        "# Add the component after the named entity recognizer\n",
        "if \"remove_stockno_suffix\" in nlp.pipe_names:\n",
        "  nlp.remove_pipe(\"remove_stockno_suffix\")\n",
        "\n",
        "nlp.add_pipe(\"remove_stockno_suffix\", after=\"ner\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.remove_stockno_suffix>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FYsX9upfqCY"
      },
      "source": [
        "# Test the trained NER model and EntityRuler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "BN0IKbXXdAAH",
        "outputId": "ce8fa9fe-da2e-4a49-bdcb-b99999f2dd5e"
      },
      "source": [
        "sentences = [\n",
        "  \"ç‡å¥½æ¸¯é¡(0066.HK)å¼·çƒˆå»ºè­°è²·å…¥ ğŸ˜\",\n",
        "  \"å…§åœ°ç–«æƒ…å—æ§,æ—…éŠç›¸é—œè‚¡åŒç¨‹è—é¾(780)æœ€è¿‘å€é–“ä¸Šè½æ©«è¡Œ,å¤§æˆ¶æ”¶é›†ä¼¼è¿‘å®Œæˆ,ä¸­ç·šæ”¯æŒä½$13.83,å¯è€ƒæ…®ä½œä¸­é•·ç·šæŠ•è³‡ã€‚\",\n",
        "  \"ç¿è¦‹æ•™è‚²ï¼ˆ6068.HKï¼‰ï¼šå‡ˆåˆ©èˆ‡ç¾é‡‘æµå¤§å¢è¶…å››æˆï¼Œä¼°å€¼å¸å¼•åŠ›å‡¸é¡¯ï¼Œç²å¤§è¡Œç‡å¤š\téš»1765éƒ½è³ºå¤šå¹¾æˆ å‡å·¦å°‘å°‘å°±è·Œå‡¸ æ”¯è‚¡å³ä¿‚æ”¯è‚¡Â  ğŸ¤· \",\n",
        "  \"å¯†åˆ‡ç•™æ„é‹¼éµè‚¡ï¼Œ581ä¸­åœ‹æ±æ–¹ï¼Œ323é¦¬é‹¼ï¼Œ347éé‹¼ï¼Œ1053é‡é‹¼ï¼Œ2600ä¸­é‹ï¼\",\n",
        "  'å…¥å·¦ä¸­å¥³ (308)  å‡å››æˆï¼Œæ”¾å®šåŠ é¦¬\tall in pk å·¦,èµ·å””ç¿»èº«  åŠ ä¸€æ³¨ ç®—, 3å…ƒèµ°äºº!  è´å’—è³¼è²· tesla é›»è»Š  è¼¸å’—å°±pk',\n",
        "  'å„ä½æ„›åœ‹äººä»•è«‹æ”¯æŒ883è™Ÿä¸­æµ·æ²¹\tæœ‰ä½ åœ°æ”¯æŒ ç›¸ä¿¡ä¸­æµ·æ²¹è‚¡åƒ¹ä»Šæ—¥å¯ä»¥è¶…è‹±è¶•ç¾  ç¯€ç¯€ä¸Šå‡ å¤šè¬å„ä½æ”¯æŒ  883 è™Ÿä¸­æµ·æ²¹ æ²¹ä¸­çŸ›å° ğŸ˜ ',\n",
        "  '1727 çµ‚æ–¼æ­¢è·Œã€‚å›å‡ä¸­ã€‚\tæ­£å¸¸ä»Šæ—¥æœƒåå½ˆæ—¢  å•é¡Œä¿‚å½ˆå®Œæœƒä¼å¾—ç©©æ”¶å¸‚å—?  è¦‹ä½¢è²·è²¨å¤šéå‡ºè²¨  ä½†éƒ½ä¿‚ä¿¾äººã©’ä½å‡5ä¸Šå»',\n",
        "  '5è™Ÿä»”å¤§ç¬¨è±¡æœ‰å†‡æ©Ÿæœƒä¼ç•ªèµ·èº«\tæ”¾å¿ƒ,æˆ‘ä¿¡ä½¢æœƒå‡ä¸Šå» Ps: 33æ–‡å…¥å’—è²¨',\n",
        "  '981ä¸­èŠ¯åœ‹éš›è½æ—¥çˆ†å‡ï¼æ·¨åˆ©æ½¤è¶…é æœŸï¼Œç¬¬äºŒå­£åº¦æ·¨åˆ©æ½¤1.38å„„ç¾å…ƒï¼Œå¸‚å ´é æœŸç›ˆåˆ©9519è¬ç¾å…ƒï¼ŒèˆŠå¹´åŒæœŸç›ˆåˆ©1854è¬ç¾å…ƒï¼ŒåŒæ¯”å¢é•·6.44å€\t35æ‡‰è©²ç„¡å•é¡Œ ä»Šæœˆä¸Šè¿”40èšŠ GOGO'\n",
        "]\n",
        "\n",
        "# def replace_zh_punctuation(sentence):\n",
        "#   str = sentence\n",
        "#   str = str.replace(\"ï¼ˆ\", \"(\")\n",
        "#   str = str.replace(\"ï¼‰\", \")\")\n",
        "#   return(str)\n",
        "\n",
        "for sentence in sentences:\n",
        "  # sentence = replace_zh_punctuation(sentence)\n",
        "  doc = nlp(sentence)\n",
        "  displacy.render(doc,style='ent',jupyter=True)\n",
        "  print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">ç‡å¥½æ¸¯é¡(\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    0066.HK\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              ")å¼·çƒˆå»ºè­°è²·å…¥ ğŸ˜</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">å…§åœ°ç–«æƒ…å—æ§,æ—…éŠç›¸é—œè‚¡åŒç¨‹è—é¾\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    (780)\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "æœ€è¿‘å€é–“ä¸Šè½æ©«è¡Œ,å¤§æˆ¶æ”¶é›†ä¼¼è¿‘å®Œæˆ,ä¸­ç·šæ”¯æŒä½$13.83,å¯è€ƒæ…®ä½œ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ä¸­é•·ç·š\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "æŠ•è³‡ã€‚</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">ç¿è¦‹æ•™è‚²ï¼ˆ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    6068.HK\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "ï¼‰ï¼šå‡ˆåˆ©èˆ‡ç¾é‡‘æµå¤§å¢è¶…å››æˆï¼Œä¼°å€¼å¸å¼•åŠ›å‡¸é¡¯ï¼Œç²å¤§è¡Œç‡å¤š\téš»\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1765\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "éƒ½è³ºå¤šå¹¾æˆ å‡å·¦å°‘å°‘å°±è·Œå‡¸ æ”¯è‚¡å³ä¿‚æ”¯è‚¡Â  ğŸ¤· </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">å¯†åˆ‡ç•™æ„é‹¼éµè‚¡ï¼Œ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    581\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "ä¸­åœ‹æ±æ–¹ï¼Œ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    323\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "é¦¬é‹¼ï¼Œ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    347\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "éé‹¼ï¼Œ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1053\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "é‡é‹¼ï¼Œ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2600\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ä¸­é‹\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "ï¼</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">å…¥å·¦ä¸­å¥³ \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    (308)\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "  å‡å››æˆï¼Œæ”¾å®šåŠ é¦¬\tall in pk å·¦,èµ·å””ç¿»èº«  åŠ ä¸€æ³¨ ç®—, 3å…ƒèµ°äºº!  è´å’—è³¼è²· tesla é›»è»Š  è¼¸å’—å°±pk</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">å„ä½æ„›åœ‹äººä»•è«‹æ”¯æŒ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    883\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "è™Ÿä¸­æµ·æ²¹\tæœ‰ä½ åœ°æ”¯æŒ ç›¸ä¿¡\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ä¸­æµ·æ²¹\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "è‚¡åƒ¹ä»Šæ—¥å¯ä»¥è¶…è‹±è¶•ç¾  ç¯€ç¯€ä¸Šå‡ å¤šè¬å„ä½æ”¯æŒ  \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    883\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              " è™Ÿä¸­æµ·æ²¹ æ²¹ä¸­çŸ›å° ğŸ˜ </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">1727 çµ‚æ–¼æ­¢è·Œã€‚å›å‡ä¸­ã€‚\tæ­£å¸¸ä»Šæ—¥æœƒåå½ˆæ—¢  å•é¡Œä¿‚å½ˆå®Œæœƒä¼å¾—ç©©æ”¶å¸‚å—?  è¦‹ä½¢è²·è²¨å¤šéå‡ºè²¨  ä½†éƒ½ä¿‚ä¿¾äººã©’ä½å‡\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    5\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "ä¸Šå»</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    5è™Ÿä»”\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG-S-A</span>\n",
              "</mark>\n",
              "\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    å¤§ç¬¨è±¡\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG-S-A</span>\n",
              "</mark>\n",
              "æœ‰å†‡æ©Ÿæœƒä¼ç•ªèµ·èº«\tæ”¾å¿ƒ,æˆ‘ä¿¡ä½¢æœƒå‡ä¸Šå» Ps: 33æ–‡å…¥å’—è²¨</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    981\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "ä¸­èŠ¯åœ‹éš›è½æ—¥çˆ†å‡ï¼æ·¨åˆ©æ½¤è¶…é æœŸï¼Œç¬¬äºŒå­£åº¦æ·¨åˆ©æ½¤1.38å„„ç¾å…ƒï¼Œå¸‚å ´é æœŸç›ˆåˆ©9519è¬ç¾å…ƒï¼ŒèˆŠå¹´åŒæœŸç›ˆåˆ©1854è¬ç¾å…ƒï¼ŒåŒæ¯”å¢é•·6.44å€\t35æ‡‰è©²ç„¡å•é¡Œ ä»Šæœˆ\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ä¸Šè¿”\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "40èšŠ GOGO</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
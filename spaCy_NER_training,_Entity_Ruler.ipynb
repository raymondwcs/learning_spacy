{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('nlp': conda)"
    },
    "interpreter": {
      "hash": "351231c1f7e72ec05ff176d4b7814d8150b7ea6b9dc70ba3501701b8f740a37d"
    },
    "colab": {
      "name": "spaCy NER training, Entity Ruler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raymondwcs/learning_spacy/blob/main/spaCy_NER_training%2C_Entity_Ruler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TcIJUPPdlzC"
      },
      "source": [
        "This example demonstrates how to use rules-augmented model-based NER to locate stock codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xmMkwz0dVMo",
        "outputId": "27ab8910-7d55-419b-d931-240756d1b8fe"
      },
      "source": [
        "!pip install --quiet -U spacy\n",
        "!python -m spacy download zh_core_web_lg\n",
        "!git clone http://github.com/raymondwcs/learning_spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.9 MB 29.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 623 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 44.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 456 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting zh-core-web-lg==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/zh_core_web_lg-3.1.0/zh_core_web_lg-3.1.0-py3-none-any.whl (603.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 603.8 MB 8.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from zh-core-web-lg==3.1.0) (3.1.3)\n",
            "Collecting spacy-pkuseg<0.1.0,>=0.0.27\n",
            "  Downloading spacy_pkuseg-0.0.28-cp37-cp37m-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 19.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (4.62.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (8.0.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.7/dist-packages (from spacy-pkuseg<0.1.0,>=0.0.27->zh-core-web-lg==3.1.0) (0.29.24)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->zh-core-web-lg==3.1.0) (2.0.1)\n",
            "Installing collected packages: spacy-pkuseg, zh-core-web-lg\n",
            "Successfully installed spacy-pkuseg-0.0.28 zh-core-web-lg-3.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('zh_core_web_lg')\n",
            "Cloning into 'learning_spacy'...\n",
            "warning: redirecting to https://github.com/raymondwcs/learning_spacy/\n",
            "remote: Enumerating objects: 219, done.\u001b[K\n",
            "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
            "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
            "remote: Total 219 (delta 123), reused 57 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (219/219), 66.23 MiB | 27.22 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMcLQHQ5dAAA"
      },
      "source": [
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "from spacy import displacy\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vnwMcEmdAAC"
      },
      "source": [
        "nlp = spacy.load('zh_core_web_lg')\n",
        "nlp.tokenizer.initialize(pkuseg_model=\"./learning_spacy/spacy_pkuseg/models\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOkZtiKAhjnQ"
      },
      "source": [
        "# Data for training the model-based NER\n",
        "Training can also be done via CLI.  Details below.\n",
        "\n",
        "https://github.com/raymondwcs/learning_spacy/tree/main/NER_Training_CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smi8zsDQdAAD"
      },
      "source": [
        "TRAIN_DATA = [\n",
        "    (\"一齊係國企成份股調整期間 大家一齊不問價掃貨 尤其是386 857 成份股佔指數比重只係5%左右 冇咩受新計法影響 挾死班歐美鬼佬 港股10月29000 遠必挾之\", \n",
        "        {\"entities\": [(26,29,\"STOCK\"),(30,33,\"STOCK\")]}),\n",
        "    (\"高盛：維持對騰訊(0700)買入評級 目標價705港元高盛發表報告指,與騰訊管理層於路演活動溝通後,重申對騰訊嘅積極正面睇法。\",\n",
        "        {\"entities\": [(6,8,\"STOCK\")]}),\n",
        "    (\"中電、匯控、恒大8月暴升8.5%。\",\n",
        "        {'entities': [(0,2,\"STOCK\"),(3,5,\"STOCK\"),(6,8,\"STOCK\")]}),\n",
        "    (\"匯控(00005)將於下周一（2日）公布2021年度中期業績。\",\n",
        "        {'entities': [(0,2,\"STOCK\")]}),\n",
        "    (\"中電，匯控，港交所齊齊跌8.5%金融海嘯後最差。\",\n",
        "        {\"entities\": [(0,2,\"STOCK\"),(3,5,\"STOCK\"),(6,9,\"STOCK\")]}),    \n",
        "    (\"港燈將恢復派息\",\n",
        "        {\"entities\": [(0,2,\"STOCK\")]})\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "451MmG4PdAAD"
      },
      "source": [
        "ner=nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Adding labels to the `ner`\n",
        "for _, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnyzPNiBhu5Y"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M0x6E4HdAAE",
        "outputId": "068e6185-d633-4200-f5ea-9718bdfb3ec8"
      },
      "source": [
        "epoch = 50\n",
        "optimizer = nlp.resume_training()\n",
        "\n",
        "# get names of other pipes to disable them during training\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "  for itn in range(epoch):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = spacy.util.minibatch(TRAIN_DATA,size=2)\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        example = []\n",
        "        for i in range(len(texts)):\n",
        "          doc = nlp.make_doc(texts[i])\n",
        "          example.append(Example.from_dict(doc, annotations[i]))\n",
        "        nlp.update(example,drop=0.2,sgd=optimizer,losses=losses)\n",
        "    print(\"Losses\", losses)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses {'ner': 27.174205583445975}\n",
            "Losses {'ner': 20.602176457318798}\n",
            "Losses {'ner': 17.820162218805145}\n",
            "Losses {'ner': 15.422787848095565}\n",
            "Losses {'ner': 14.271302128220004}\n",
            "Losses {'ner': 12.36997590793824}\n",
            "Losses {'ner': 11.812037936693876}\n",
            "Losses {'ner': 7.068529113365521}\n",
            "Losses {'ner': 3.0906280035020757}\n",
            "Losses {'ner': 2.343405767949662}\n",
            "Losses {'ner': 0.47858492012588627}\n",
            "Losses {'ner': 0.08122197914558081}\n",
            "Losses {'ner': 0.18780374568056063}\n",
            "Losses {'ner': 0.21515904354306098}\n",
            "Losses {'ner': 0.25429279631817703}\n",
            "Losses {'ner': 0.0004915435000139884}\n",
            "Losses {'ner': 1.796596378614676e-05}\n",
            "Losses {'ner': 0.8312920596870434}\n",
            "Losses {'ner': 7.568776269697458e-05}\n",
            "Losses {'ner': 2.750554704010387e-06}\n",
            "Losses {'ner': 6.112969720922181e-07}\n",
            "Losses {'ner': 1.629736456224959e-05}\n",
            "Losses {'ner': 6.067612626545516e-07}\n",
            "Losses {'ner': 2.900375534370305e-05}\n",
            "Losses {'ner': 4.359029867693783e-08}\n",
            "Losses {'ner': 3.781668739592886e-08}\n",
            "Losses {'ner': 6.021872108463889e-06}\n",
            "Losses {'ner': 1.5779574492796045e-07}\n",
            "Losses {'ner': 0.017631711086331246}\n",
            "Losses {'ner': 5.5202232756708365e-06}\n",
            "Losses {'ner': 0.023839343724558155}\n",
            "Losses {'ner': 8.296018956806249e-10}\n",
            "Losses {'ner': 4.291503209424527e-09}\n",
            "Losses {'ner': 4.980503055105384e-09}\n",
            "Losses {'ner': 3.2653070258533114e-08}\n",
            "Losses {'ner': 1.9134832781127947e-07}\n",
            "Losses {'ner': 7.210064894803727e-11}\n",
            "Losses {'ner': 1.360865012172391e-07}\n",
            "Losses {'ner': 1.3658911722791342e-08}\n",
            "Losses {'ner': 4.658910551517449e-06}\n",
            "Losses {'ner': 1.7410355041123025e-08}\n",
            "Losses {'ner': 2.0367899907824284e-05}\n",
            "Losses {'ner': 7.509171710758096e-09}\n",
            "Losses {'ner': 0.002620198197334645}\n",
            "Losses {'ner': 3.786341595077299e-09}\n",
            "Losses {'ner': 1.9177596146037133e-07}\n",
            "Losses {'ner': 3.976908739039148e-08}\n",
            "Losses {'ner': 5.367065038053944e-09}\n",
            "Losses {'ner': 3.877873400061176e-07}\n",
            "Losses {'ner': 3.0021613743035965e-10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMezKSPYe7sN"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHvgsUX8dAAF"
      },
      "source": [
        "for text, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    # print(text,ent)\n",
        "    # print(text[ent[0]:ent[1]])\n",
        "    doc = nlp(text)\n",
        "    char_span = doc.char_span(ent[0],ent[1])\n",
        "    if char_span is None:  # start and end don't map to tokens\n",
        "        print(\"Misaligned tokens\", text, ent)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTnedeX8fDKV"
      },
      "source": [
        "# Save trained model to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXhK4SAvdAAG"
      },
      "source": [
        "nlp.to_disk('./ner_model')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h3GnKT2fIlT"
      },
      "source": [
        "# Load trained model from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F-h5fEhMqsj"
      },
      "source": [
        "nlp = spacy.load('./ner_model')\n",
        "nlp.tokenizer.initialize(pkuseg_model=\"./learning_spacy/spacy_pkuseg/models\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9P4z0cBM1xj"
      },
      "source": [
        "# Define custom rules for EntityRuler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTcU3mk1dAAG"
      },
      "source": [
        "patterns = [\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"IS_DIGIT\": True},{\"ORTH\":\".\"},{\"ORTH\": \"HK\"}]},\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"IS_DIGIT\": True},{\"ORTH\":\".\"},{\"ORTH\": \"HK\"}]},\n",
        "    {\"label\": \"STOCK\", \"pattern\": [{\"TEXT\": {\"REGEX\":\"\\d+\\.HK\"}}]},\n",
        "    # {\"label\": \"STOCK\", \"pattern\": [{\"TEXT\": \"（\"},{\"IS_DIGIT\": True},{\"TEXT\": \"）\"}]},\n",
        "    # {\"label\": \"STOCK\", \"pattern\": [{'lower': {'IN': ['581','323','347','1053','2600']}}]},\n",
        "    # {\"label\": \"ORG\", \"pattern\": [{'ORTH': {'IN': ['中國東方','馬鋼','重鋼','中鋁','鞍鋼']}}]},\n",
        "    # {\"label\": \"STOCK\", \"pattern\": [{\"IS_DIGIT\": True},{\"ENT_TYPE\": \"ORG\"}]},\n",
        "    {\"label\": \"STOCK2\", \"pattern\": [{\"POS\": \"NUM\"},{\"POS\": \"NOUN\"}]},\n",
        "]\n",
        "\n",
        "if \"entity_ruler\" in nlp.pipe_names:\n",
        "  nlp.remove_pipe(\"entity_ruler\")\n",
        "\n",
        "entity_ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
        "entity_ruler.add_patterns(patterns)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOJnEtLcjpf"
      },
      "source": [
        "# Remove the noun suffix from entity label 'STOCK2'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adxyitSpPqZs",
        "outputId": "b213f82c-1594-4caf-bbbc-d37af06768f7"
      },
      "source": [
        "from spacy.language import Language\n",
        "from spacy.tokens import Span\n",
        "\n",
        "@Language.component(\"remove_stockno_suffix\")\n",
        "def remove_stockno_suffix(doc):\n",
        "    new_ents = []\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"STOCK2\":  #and ent.start != 0:\n",
        "            next_token = doc[ent.start + 1]\n",
        "            if next_token.pos_ == \"NOUN\":\n",
        "                new_ent = Span(doc, ent.start, ent.end - 1, label=\"STOCK\")\n",
        "                new_ents.append(new_ent)\n",
        "        else:\n",
        "            new_ents.append(ent)\n",
        "    doc.ents = new_ents\n",
        "    return doc\n",
        "\n",
        "# Add the component after the named entity recognizer\n",
        "if \"remove_stockno_suffix\" in nlp.pipe_names:\n",
        "  nlp.remove_pipe(\"remove_stockno_suffix\")\n",
        "\n",
        "nlp.add_pipe(\"remove_stockno_suffix\", after=\"ner\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.remove_stockno_suffix>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FYsX9upfqCY"
      },
      "source": [
        "# Test the trained NER model and EntityRuler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "BN0IKbXXdAAH",
        "outputId": "6dde1d14-e7a0-460f-d52c-6bf35d8cd525"
      },
      "source": [
        "sentences = [\n",
        "  \"睇好港鐡(0066.HK)強烈買入 😎\",\n",
        "  \"內地疫情受控,旅遊相關股同程藝龍(780)最近區間上落橫行,大戶收集似近完成,中線支持位$13.83,可考慮作中長線投資。\",\n",
        "  \"睿見教育（6068.HK）：凈利與現金流大增超四成，估值吸引力凸顯，獲大行睇多\t隻1765都賺多幾成 升左少少就跌凸 支股即係支股  🤷 \",\n",
        "  \"密切留意鋼鐵股，581中國東方，323馬鋼，347鞍鋼，1053重鋼，2600中鋁！\",\n",
        "]\n",
        "\n",
        "# def replace_zh_punctuation(sentence):\n",
        "#   str = sentence\n",
        "#   str = str.replace(\"（\", \"(\")\n",
        "#   str = str.replace(\"）\", \")\")\n",
        "#   return(str)\n",
        "\n",
        "for sentence in sentences:\n",
        "  # sentence = replace_zh_punctuation(sentence)\n",
        "  doc = nlp(sentence)\n",
        "  displacy.render(doc,style='ent',jupyter=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">睇好港鐡(\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    0066.HK\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              ")強烈買入 😎</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">內地疫情受控,旅遊相關股同程藝龍(780)最近區間上落橫行,大戶收集似近完成,中線支持位$13.83,可考慮作\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    中長線\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "投資。</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    睿見\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "教育（\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    6068.HK\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "）：凈利與現金流大增超四成，估值吸引力凸顯，獲大行睇多\t隻1765都賺多幾成 升左少少就跌凸 支股即係支股  🤷 </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">密切留意鋼鐵股，\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    581\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "中國東方，\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    323\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "馬鋼，347鞍鋼，\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1053\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "重鋼，2600\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    中鋁\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
              "</mark>\n",
              "！</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}